{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd6b6a0-c6f2-4575-a68a-811ea7baee7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace64271-8d7e-498b-bc01-ed9cefcb0437",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "import psutil\n",
    "import numpy as np\n",
    "import time\n",
    "from loguru import logger\n",
    "\n",
    "import pandas as pd\n",
    "# import scanpy as sc\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import sys\n",
    "import multiprocessing\n",
    "import anndata as ad\n",
    "import gc\n",
    "import pickle\n",
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "root_path = os.path.abspath('/home/chenyx/scMulan/cellgpt_v1/')\n",
    "sys.path.append(os.path.abspath(root_path))\n",
    "\n",
    "# from imp import reload\n",
    "# reload(hf_tokenizer) # also reload(mymodule)\n",
    "\n",
    "# from utils.hf_tokenizer import cellGenesisTokenizer\n",
    "\n",
    "#data_root_path = '/home/bianhaiyang/tmp_dataHub/datasets/'\n",
    "#dataset = 'ECA_GO'\n",
    "#dataPath = os.path.join(data_root_path,dataset)\n",
    "dataPath = \"/home/bianhaiyang/tmp_dataHub/datasets/\"\n",
    "assert os.path.exists(dataPath)\n",
    "tmp_dataPath = os.path.join(dataPath,'tmp_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229e4c04-208c-4c36-a1b9-092b26ee30f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297875e8-2757-4dfe-aa68-9307bbd7d5c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.hf_tokenizer import cellGenesisTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859eb338-d6f2-428b-88cd-040153864e1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model.model import GPTConfig, cellGPTModel\n",
    "import torch.nn.functional as F\n",
    "from model import model_kvcache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d549d54-936b-4ba7-bc3c-a05ff3bf1c92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta_info = torch.load(os.path.join(dataPath,'meta_info.pt'))\n",
    "chars = meta_info['token_set']\n",
    "tokenizer = cellGenesisTokenizer(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646540b8-3d85-4d25-a27a-31d52e4b3623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_express_level = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc91180b-4253-4671-815c-78cdf8a258fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "from tools.generation.denovoGeneration import generate_denovo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e50606-5617-49c7-9447-2934dbaca50c",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116e2aac-c4ce-44f2-8b0f-0f4a35c6b715",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8406cd-a6e4-45bf-be1d-de590fbf2b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_for_cg(idx,meta_data,meta_pool):\n",
    "    meta_num = torch.randint(0,len(meta_pool),(1,)).item()\n",
    "    task_cols = meta_pool[meta_num]\n",
    "    metadata_series = meta_data.loc[idx, task_cols]\n",
    "    metadata_list = metadata_series.tolist()\n",
    "    while 'Unclassified' in metadata_list:\n",
    "        meta_num = torch.randint(0,len(meta_pool),(1,)).item()\n",
    "        task_cols = meta_pool[meta_num]\n",
    "        metadata_series = meta_data.loc[idx, task_cols]\n",
    "        metadata_list = metadata_series.tolist()\n",
    "    return metadata_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab148854-bdac-45f6-a0a6-646d63a6dff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binned_expression(row,n_expression_level):\n",
    "    max_expr = row.max()\n",
    "    bins = np.linspace(0, max_expr, n_expression_level + 1)\n",
    "    binned_expr = np.digitize(row, bins, right=True) \n",
    "    return pd.Series(binned_expr/n_expression_level, index=row.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad190e27-9630-4c55-afe5-c49d855c0cc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_cellsentence_ele_to_df(cellGene_ele, n_expression_level, task = 'cs'):\n",
    "    dfList = []\n",
    "    ## fetch gene expression\n",
    "    for c,e in tqdm(cellGene_ele):\n",
    "        st = c.index(2207)+1\n",
    "        c_list = tokenizer.convert_ids_to_tokens(c[st:-1])\n",
    "        ele = e[st:-1]\n",
    "        dfDict = {}\n",
    "        for name,ele in zip(c_list,ele):\n",
    "            dfDict[name] = ele/n_expression_level\n",
    "        dfList.append(dfDict)\n",
    "    gDF = pd.DataFrame(dfList).fillna(0)\n",
    "    return gDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fd855a-00df-4a87-ac5c-53a31f6582f4",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1452ca6-0e43-46b0-b9d5-6bf83431d46d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model.model import GPTConfig, cellGPTModel\n",
    "import torch.nn.functional as F\n",
    "from model.model_kvcache import cellGPTModel_kv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ece53e-ac8a-479e-b3e2-c3e82c64d459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ckp = torch.load('/nfs/public/cell_gpt_data/dataHub/datasets/datasets/ECA_GO/model_hub/ckpt245000.pt')\n",
    "# ckp['model_args'].pop('beta')\n",
    "gptconf = GPTConfig(**ckp['model_args'])\n",
    "model_kv = cellGPTModel_kv(gptconf)\n",
    "model_kv = model_kv.cuda()\n",
    "model_kv.load_state_dict(ckp['model'])\n",
    "model_kv.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4989d5-e9fb-4fae-86ba-c30ed5bdfdae",
   "metadata": {
    "tags": []
   },
   "source": [
    "### generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c4147d-bac5-4966-b400-25fe0f93b1dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pack_arg(arg,n_process):\n",
    "    return [arg for _ in range(n_process)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05172078-dc4d-4c50-bd16-d64417e84f2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac03de7-0bf6-4fcc-95c0-4ed2a24ebf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combinations(base_dict, variable1_name, variable2_name, start_value, end_value, step):\n",
    "    # Initialize the list\n",
    "    combinations = []\n",
    "    \n",
    "    # Generat the combination of different level of 'GJA5' 和 'PLVAP'\n",
    "    for value1 in range(int(start_value * n_express_level), int((end_value + step) * n_express_level), int(step * n_express_level)):\n",
    "        for value2 in range(int(start_value * n_express_level), int((end_value + step) * n_express_level), int(step * n_express_level)):\n",
    "            new_dict = base_dict.copy()\n",
    "            new_dict[variable1_name] = value1\n",
    "            new_dict[variable2_name] = value2\n",
    "            combinations.append(new_dict)\n",
    "    \n",
    "    return combinations\n",
    "    \n",
    "def repeat_combinations(combinations, n):\n",
    "    repeated_list = []\n",
    "    for _ in range(n):\n",
    "        repeated_list.extend(combinations)\n",
    "    return repeated_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afe92d1-adfc-4603-bca7-bc749123f69c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dict = {'Heart': 0, 'Vascular endothelial cell': 0, '<SPToken1>': 0}\n",
    "\n",
    "# select genes\n",
    "variable1_name = 'GJA5'\n",
    "variable2_name = 'PLVAP'\n",
    "\n",
    "# set range and step_length\n",
    "start_value = 0.0\n",
    "end_value = 1\n",
    "step = 0.1\n",
    "\n",
    "combinations = generate_combinations(base_dict, variable1_name, variable2_name, start_value, end_value, step)\n",
    "combinations.append(base_dict)\n",
    "\n",
    "repeat_n = 200\n",
    "repeated_combinations = repeat_combinations(combinations, repeat_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c630fc9-5a82-45c4-9f6a-a007c7a3eaa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__': \n",
    "    multiprocessing.set_start_method('spawn', force=True)\n",
    "    print('当前母进程: {}'.format(os.getpid()))\n",
    "    start = time.time()\n",
    "    gamma = 0.1 \n",
    "    use_gpu_device = [0, 1, 2, 3] \n",
    "    n_process_in_each_gpu = 3 \n",
    "    ckp_path = '/nfs/public/cell_gpt_data/modelHub/full_model/ckpt135000.pt' \n",
    "    results_dir = f'/nfs/public/cell_gpt_data/dataHub/generated_cells/VEC_Gradient_FullLength/'\n",
    "    world_size = len(use_gpu_device)\n",
    "    n_process = n_process_in_each_gpu * world_size\n",
    "    process_idx = list(range(n_process))\n",
    "    devices = [device for device in use_gpu_device for _ in range(n_process_in_each_gpu)]    \n",
    "    print(\"devices: \",devices)\n",
    "\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.mkdir(results_dir)\n",
    "    results_save_dir = results_dir + 'generate_01gamma_'\n",
    "    meta_data_organ = None\n",
    "\n",
    "    idxs = np.array_split(repeated_combinations, n_process)\n",
    "    idxs = [list(idx) for idx in idxs]\n",
    "\n",
    "\n",
    "    gammas = pack_arg(gamma,n_process)\n",
    "    force_meta = pack_arg(True, n_process) \n",
    "\n",
    "    meta_terms = pack_arg(\n",
    "         \"FulLength\"\n",
    "        ,n_process)\n",
    "\n",
    "    meta_organs = pack_arg(meta_data_organ,n_process)\n",
    "\n",
    "    ckp_paths = pack_arg(ckp_path,n_process)\n",
    "    results_save_dirs = [results_save_dir+str(process_id)+'results.pt' for _,process_id in zip(devices,process_idx)]\n",
    "\n",
    "    args = [(idx, device, gamma, meta_organ, ckp_path, save_path, meta_term, force) \\\n",
    "            for idx, device, gamma, meta_organ,ckp_path,save_path,meta_term, force in \\\n",
    "            zip(idxs, devices,gammas, meta_organs, ckp_paths,results_save_dirs,meta_terms, force_meta)]\n",
    "    with Pool(n_process) as pool:\n",
    "        pool.map(generate_denovo.generate, args)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Generation Finished, 总共用时{}秒\".format((end - start)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scMulan",
   "language": "python",
   "name": "scmulan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
